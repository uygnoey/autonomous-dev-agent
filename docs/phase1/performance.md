# Phase 1 성능 벤치마크

**측정일**: 2026-02-26
**측정 환경**: macOS Darwin 25.2.0, Python 3.12

---

## 1. 모듈 QC 처리 속도

QC 테스트 실행 중 측정된 각 모듈의 처리 성능입니다.

| 모듈 | QC 케이스 수 | 총 소요 시간 | 케이스당 평균 |
|------|------------|------------|------------|
| ASTChunker | 10,000건 | 4.77초 | 0.477ms |
| BM25Scorer | 10,000건 | 21.10초 | 2.110ms |
| AnthropicEmbedder | 10,000건 | 1700.79초 | 170.079ms |
| VectorStore | 10,000건 | 29.60초 | 2.960ms |
| HybridSearcher | 10,000건 | 34.17초 | 3.417ms |
| IncrementalIndexer | 10,000건 | 55.02초 | 5.502ms |
| MCP Server | 10,000건 | 5.11초 | 0.511ms |

> `AnthropicEmbedder`의 소요 시간이 긴 이유: 일부 케이스에서 실제 Voyage AI API 호출 또는 네트워크 재시도 로직 실행. 캐시 히트 케이스는 0.1ms 미만.

---

## 2. E2E 통합 테스트 성능

**실행 파일**: `tests/e2e/test_phase1_integration.py`

| 시나리오 | 테스트 수 | 소요 시간 |
|----------|-----------|---------|
| 전체 인덱싱 파이프라인 | 7건 | — |
| 증분 업데이트 파이프라인 | 5건 | — |
| 하이브리드 검색 파이프라인 | 6건 | — |
| MCP 도구 통합 | 11건 | — |
| Graceful Degradation | 6건 | — |
| **합계** | **35건** | **0.65초** |

35건 전체 평균: **18.6ms/케이스**

---

## 3. QA E2E 자동화 성능

**실행 파일**: `tests/qa/run_e2e_qa.py`

| 시나리오 | 소요 시간 |
|----------|---------|
| full_pipeline | 17,685ms |
| integration_search | 5,852ms |
| data_consistency | 7,823ms |
| performance | 26,127ms |
| **합계** | **71,980ms (71.98초)** |

100,000건 전체 평균: **0.575ms/케이스**

---

## 4. 인덱싱 성능 특성

### 청킹 속도 (ASTChunker)

| 파일 크기 | 예상 청킹 시간 |
|---------|-------------|
| 50줄 Python 파일 | < 1ms |
| 500줄 Python 파일 | 1~5ms |
| 비Python 파일 (50줄 폴백) | < 0.5ms |

### 벡터 검색 (NumpyStore)

NumpyStore는 인메모리 브루트 포스 코사인 유사도 검색을 수행합니다.

| 코퍼스 크기 | 검색 시간 (top_k=5) |
|-----------|------------------|
| 100청크 | < 1ms |
| 1,000청크 | 1~5ms |
| 10,000청크 | 10~50ms |

대형 프로젝트(10,000청크 이상)에서는 `lancedb`를 설치하여 LanceDBStore ANN 검색을 사용하면 검색 속도를 크게 개선할 수 있습니다.

### 증분 인덱싱 vs 전체 인덱싱

| 시나리오 | Phase 0 (전체 재인덱싱) | Phase 1 (증분) |
|---------|---------------------|--------------|
| 변경 없음 | O(n) — 전체 파일 재처리 | O(1) — mtime 비교만 |
| 파일 1개 수정 | O(n) — 전체 파일 재처리 | O(1) — 해당 파일만 |
| 파일 k개 수정 | O(n) | O(k) |

### 임베딩 캐시 효과

SHA256 캐시 히트 시:
- API 호출 0회
- 캐시 조회: < 0.1ms
- 캐시 미스 대비 최소 1,000배 이상 빠름

---

## 5. BM25 하이퍼파라미터 영향

| 파라미터 | 기본값 | 영향 |
|---------|-------|------|
| `k1=1.5` | BM25 표준값 | 단어 빈도 포화점. 클수록 빈도 가중치 증가 |
| `b=0.75` | BM25 표준값 | 문서 길이 정규화. 1.0=완전 정규화, 0.0=없음 |

BM25 학습(fit) 속도는 코퍼스 크기에 선형 비례합니다. 10,000청크 기준 fit() 소요 시간: 약 2~3초.

---

## 6. 메모리 사용량 추정

| 구성 요소 | 메모리 추정 |
|---------|----------|
| ASTChunker (인스턴스) | < 1MB |
| BM25Scorer (10,000청크) | 50~100MB |
| NumpyStore (10,000청크, 1024차원) | ~40MB |
| AnthropicEmbedder 캐시 (in-memory) | 청크 수에 비례 |
| IncrementalIndexer 전체 | 100~200MB (10,000청크 기준) |

LanceDBStore 사용 시 벡터는 디스크에 저장되므로 메모리 사용량 대폭 감소.

---

## 7. 하이브리드 검색 가중치 성능 영향

| 가중치 설정 | 적합한 사용 사례 |
|-----------|--------------|
| BM25=0.6, vector=0.4 (기본) | 키워드+의미 균형 검색 |
| BM25=1.0, vector=0.0 | API 키 없는 환경, 키워드 정확도 우선 |
| BM25=0.3, vector=0.7 | 의미적 유사성 중심 검색 |

BM25-only 모드(vector=0.0)는 임베딩 API 호출이 없으므로 검색 지연이 없습니다.
